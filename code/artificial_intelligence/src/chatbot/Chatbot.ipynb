{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ5qZbOambNh"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mjisqmlmRk8",
        "outputId": "c28ec844-ece8-4961-f054-cb4fb4e7d157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk #for tokenization, stemming and vectorization of words\n",
        "nltk.download('punkt') #for the first time\n",
        "from nltk.stem.porter import PorterStemmer # for stemming\n",
        "import json #for reading and manipulating training data\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random #for random results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpZlpCcqsMjM"
      },
      "source": [
        "# **Creating Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ItxwbvTymmVg"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dSkLLZbJmomO"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "31ShRSAZmyKP"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "  \"\"\"\n",
        "  Argument:\n",
        "  sentence : [\"hello\", \"how\", \"are\", \"you\"]\n",
        "  all_words : [\"hi\", \"hello\", \"I\", \"you\", \"thank\", \"cool\"]\n",
        "\n",
        "  Returns:\n",
        "  bag = [0, 1, 0, 1, 0, 0] \n",
        "  \"\"\"\n",
        "  tokenized_sentence= [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "  bag = np.zeros(len(all_words), dtype = np.float32) \n",
        "\n",
        "  for idx, w in enumerate(all_words):\n",
        "    if w in tokenized_sentence:\n",
        "      bag[idx] = 1.0\n",
        "\n",
        "  return bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74a_bZ1sqmLG",
        "outputId": "2a70a34f-14ca-4b2d-c6eb-7718a954eab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words:  [\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n",
            "Tags:  ['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n",
            "Xtrain:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 1.]]\n",
            "YTrain:  [3 3 3 3 3 3 2 2 2 6 6 6 6 4 4 4 5 5 5 5 0 0 0 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "with open('intents.json', \"r\") as file:\n",
        "  intents = json.load(file)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "data = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "  tag = intent['tag']\n",
        "  tags.append(tag)\n",
        "  for pattern in intent['patterns']:\n",
        "    w = tokenize(pattern)\n",
        "    all_words.extend(w)\n",
        "    data.append((w, tag))\n",
        "\n",
        "ignore_words = ['?', \"!\", \".\", \",\"] #remove punctionations\n",
        "\n",
        "all_words = [stem(word) for word in all_words if word not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "print(\"Words: \", all_words)\n",
        "print(\"Tags: \", tags)\n",
        "\n",
        "x_train = [] #bag of words\n",
        "y_train = [] #tag numbers\n",
        "\n",
        "for pattern_sentence, tag in data:\n",
        "  bag = bag_of_words(pattern_sentence, all_words)\n",
        "  x_train.append(bag)\n",
        "\n",
        "  class_label = tags.index(tag) \n",
        "  y_train.append(class_label) \n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\"Xtrain: \", x_train)\n",
        "print(\"YTrain: \", y_train) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3JKdE09J50"
      },
      "source": [
        "# **Dataset class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1ecCjrFHry_r"
      },
      "outputs": [],
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.n_samples = len(x_train)\n",
        "    self.x_data = x_train\n",
        "    self.y_data = y_train\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return (self.x_data[index], self.y_data[index])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kej75I1M9IuT"
      },
      "source": [
        "# **Hyper parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXx2wCnU9REF",
        "outputId": "d77ae677-9f1e-414e-bbbe-17bdbad19a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "INPUT_SIZE = len(all_words) #or len(x_train[0])\n",
        "HIDDEN_SIZE = 8\n",
        "OUTPUT_SIZE = len(tags) #no of classes\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 1000\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "FILE = \"data.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ajFcXiv_9Gcu"
      },
      "outputs": [],
      "source": [
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset = dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkZGONQp9qEs"
      },
      "source": [
        "# **Architecture and Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uAG5MdVd9gY8"
      },
      "outputs": [],
      "source": [
        "class NNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out) \n",
        "    out = self.l3(out)\n",
        "    #no activation and no softmax\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jpV7X0AC-1iF"
      },
      "outputs": [],
      "source": [
        "model = NNet(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f6zchUPAS8E"
      },
      "source": [
        "# **Loss function and optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mM84VIzq_Ss1"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdBeS6-LAtYh"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT66QhP0AoBu",
        "outputId": "d7120795-7b3e-4a7f-f6cb-80542e71bb5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/1000, loss = 1.5947\n",
            "Epoch 200/1000, loss = 0.5184\n",
            "Epoch 300/1000, loss = 0.0091\n",
            "Epoch 400/1000, loss = 0.0103\n",
            "Epoch 500/1000, loss = 0.0011\n",
            "Epoch 600/1000, loss = 0.0008\n",
            "Epoch 700/1000, loss = 0.0038\n",
            "Epoch 800/1000, loss = 0.0007\n",
            "Epoch 900/1000, loss = 0.0012\n",
            "Epoch 1000/1000, loss = 0.0003\n",
            "Final loss = 0.0003\n",
            "Training complete... file saved to data.pth\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  for words, labels in train_loader:\n",
        "    words = words.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(words)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad() #empty the gradient before calculating gradient for every epoch\n",
        "    loss.backward() #run back prop\n",
        "    optimizer.step() #update parameters\n",
        "\n",
        "  if(epoch + 1) % 100 == 0:\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}, loss = {loss.item():.4f}')\n",
        "\n",
        "model_data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": INPUT_SIZE,\n",
        "    \"output_size\": OUTPUT_SIZE,\n",
        "    \"hidden_size\": HIDDEN_SIZE,\n",
        "    \"all_words\": all_words,\n",
        "    \"tags\": tags,\n",
        "}\n",
        "\n",
        "print(f'Final loss = {loss.item():.4f}')\n",
        "torch.save(model_data, FILE)\n",
        "print(f\"Training complete... file saved to {FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwDlPLSsD9_s"
      },
      "source": [
        "# **ChatBOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umtH77j9DW2P",
        "outputId": "2365e5cb-73aa-434f-8821-247bdb63c9af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model_data = torch.load(FILE) #loading model\n",
        "\n",
        "model_state = final_model_data[\"model_state\"]\n",
        "all_words = final_model_data[\"all_words\"]\n",
        "\n",
        "best_model = NNet(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
        "best_model.load_state_dict(model_state)\n",
        "best_model.eval() #change to evalutation stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJbnC_2BDcUX",
        "outputId": "2e180598-e141-41f9-93d8-261678d8baea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! type 'quit to exit\n",
            "You: Hello\n",
            "STARY: Hi there, how can I help?\n",
            "You: WHat do you sell?\n",
            "STARY: We sell coffee and tea\n",
            "You: Nice. How long does shipping take?\n",
            "STARY: Shipping takes 2-4 days\n",
            "You: Ok. \n",
            "STARY: Sorry, I do not understand...\n",
            "You: thanks\n",
            "STARY: Any time!\n",
            "You: see you\n",
            "STARY: Have a nice day\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "BOT_NAME = \"STARY\"\n",
        "print(\"Let's chat! type 'quit to exit\")\n",
        "\n",
        "while True:\n",
        "  sentence = input(\"You: \")\n",
        "  if(sentence == 'quit'):\n",
        "    break\n",
        "  \n",
        "  #tokenize and bag of words, same as training\n",
        "  sentence = tokenize(sentence)\n",
        "  x = bag_of_words(sentence, all_words)\n",
        "  x = x.reshape(1, x.shape[0])\n",
        "  x= torch.from_numpy(x).to(DEVICE)\n",
        "\n",
        "  output = best_model(x)\n",
        "  _, predicted = torch.max(output, dim = 1)\n",
        "  tag = tags[predicted.item()] #get tag of the sentence spoken by user\n",
        "  \n",
        "  #to get probabilities of outputs\n",
        "  probs = torch.softmax(output, dim = 1)\n",
        "  prob = probs[0][predicted.item()]\n",
        "  if(prob.item() > 0.75): \n",
        "    #loop through all tags in intent to select a random sentence from responses of that specific tag\n",
        "    for intent in intents[\"intents\"]:\n",
        "      if tag == intent[\"tag\"]:\n",
        "        print(f\"{BOT_NAME}: {random.choice(intent['responses'])}\")\n",
        "  else:\n",
        "    print(f\"{BOT_NAME}: Sorry, I do not understand...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
