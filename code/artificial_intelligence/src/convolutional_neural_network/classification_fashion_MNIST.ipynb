{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#This notebook classifies the Fashion-MNIST dataset\n\n# Import all necessary libraries\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Define a transform for the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,))])\n\n# Download and load the training data\ntrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\n# Download and load the test data\ntestset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Define your network architecture.\nclass Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fn1 = nn.Linear(784, 256)\n        self.fn2 = nn.Linear(256, 128)\n        self.fn3 = nn.Linear(128, 64)\n        self.fn4 = nn.Linear(64, 10)\n        \n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(self.fn1(x))\n        x = F.relu(self.fn2(x))\n        x = F.relu(self.fn3(x))\n        x = F.log_softmax(self.fn4(x), dim=1)\n        \n        return x"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Define the network, loss criterion and optimizer\n\nmodel = Classifier()\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.003)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"epochs = 30\nsteps = 0\n\ntrain_losses, test_losses = [], []\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in trainloader:\n        \n        optimizer.zero_grad()\n        \n        log_ps = model(images)\n        loss = criterion(log_ps, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n    else:\n        test_loss = 0\n        accuracy = 0\n        \n        # Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n            for images, labels in testloader:\n                log_ps = model(images)\n                test_loss += criterion(log_ps, labels)\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n                \n        train_losses.append(running_loss/len(trainloader))\n        test_losses.append(test_loss/len(testloader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def plot_results(image, ps):\n    # This function is to view an image and it's predicted class.\n    \n    ps = ps.data.numpy().squeeze()\n    \n    f, (ax1, ax2) = plt.subplots(figsize=(10, 10), ncols=2)\n    ax1.imshow(image.resize_(1,28,28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(['T-shirt/Top',\n                        'Trouser',\n                        'Pullover',\n                        'Dress',\n                        'Coat',\n                        'Sandal',\n                        'Shirt',\n                        'Sneaker',\n                        'Bag',\n                        'Ankle Boot'], size='medium')\n    ax2.set_title('Probability of classes')\n    ax2.set_xlim(0,1.1)\n    \n    plt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Each time you hit enter, next image is loaded\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[1]\n\n# TODO: Calculate the class probabilities (softmax) for img\nps = torch.exp(model(img))\n\n# Plot the image and probabilities\nplot_results(img, ps)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}